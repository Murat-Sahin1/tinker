{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41886cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f75b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nparser = argparse.ArgumentParser(descri\\n                                 ption='Load a TensorFlow model and evaluate.')\\nparser.add_argument('--model_path', type=str, required=True,\\n                    help='Path to the TensorFlow .h5 model file')\\nparser.add_argument('--input', type=str, nargs='+', required=True,\\n                    help='Input to the model, separated by spaces')\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "parser = argparse.ArgumentParser(descri\n",
    "                                 ption='Load a TensorFlow model and evaluate.')\n",
    "parser.add_argument('--model_path', type=str, required=True,\n",
    "                    help='Path to the TensorFlow .h5 model file')\n",
    "parser.add_argument('--input', type=str, nargs='+', required=True,\n",
    "                    help='Input to the model, separated by spaces')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2938fb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nargs = parser.parse_args()\\nprint(args.input[0])\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "args = parser.parse_args()\n",
    "print(args.input[0])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "632a4423",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_relative_path = \"../AiModelfiles/9949f73c-921a-41c7-9665-e1eba160a4e1/9949f73c-921a-41c7-9665-e1eba160a4e1.h5\"\n",
    "input_relative_path = \"../AiModelfiles/9949f73c-921a-41c7-9665-e1eba160a4e1/InputFiles/Image\"\n",
    "evaluation_relative_path = \"../AiModelfiles/9949f73c-921a-41c7-9665-e1eba160a4e1/Evaluation/InitialEvaluation\"\n",
    "csv_relative_path = \"../AiModelfiles/9949f73c-921a-41c7-9665-e1eba160a4e1/yValues/yVal.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9c97cd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Voul\\tinker\\tinker\\tinker.Infrastructure\\ScriptHandlers\\../AiModelfiles/9949f73c-921a-41c7-9665-e1eba160a4e1/InputFiles/Image\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(os.getcwd(), model_relative_path)\n",
    "\n",
    "evaluation_path = os.path.join(os.getcwd(), evaluation_relative_path)\n",
    "image_path = os.path.join(os.getcwd(), input_relative_path)\n",
    "\n",
    "csv_path = os.path.join(os.getcwd(), csv_relative_path)\n",
    "print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c8f578a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "41c16d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Voul\\tinker\\tinker\\tinker.Infrastructure\\ScriptHandlers\\../AiModelfiles/9949f73c-921a-41c7-9665-e1eba160a4e1/InputFiles/Image\\0.jpeg\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "C:\\Users\\Voul\\tinker\\tinker\\tinker.Infrastructure\\ScriptHandlers\\../AiModelfiles/9949f73c-921a-41c7-9665-e1eba160a4e1/InputFiles/Image\\1.jpeg\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "C:\\Users\\Voul\\tinker\\tinker\\tinker.Infrastructure\\ScriptHandlers\\../AiModelfiles/9949f73c-921a-41c7-9665-e1eba160a4e1/InputFiles/Image\\2.jpeg\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "C:\\Users\\Voul\\tinker\\tinker\\tinker.Infrastructure\\ScriptHandlers\\../AiModelfiles/9949f73c-921a-41c7-9665-e1eba160a4e1/InputFiles/Image\\3.jpeg\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "C:\\Users\\Voul\\tinker\\tinker\\tinker.Infrastructure\\ScriptHandlers\\../AiModelfiles/9949f73c-921a-41c7-9665-e1eba160a4e1/InputFiles/Image\\4.jpeg\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "All predictions: [2.4403998821753703e-08, 0.36011770367622375, 0.6398240923881531, 5.814163887407631e-05]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for filename in os.listdir(image_path):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
    "        temp_path = os.path.join(image_path, filename)\n",
    "        print(temp_path)\n",
    "        image = tf.keras.preprocessing.image.load_img(temp_path, target_size=(224, 224))\n",
    "        image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "        image = tf.expand_dims(image, axis=0)\n",
    "        \n",
    "        predictions = model.predict(image).tolist()\n",
    "        predictions = predictions[0]\n",
    "        \n",
    "print('All predictions:', predictions)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b285fd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3']\n",
      "[0, 0, 1, 1]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "indexes = []\n",
    "y_values = []\n",
    "class_count = 0\n",
    "with open(csv_path, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    i=0;\n",
    "    \n",
    "    for row in reader:\n",
    "        for value in row:\n",
    "            i = i + 1;\n",
    "            if i == 1:\n",
    "                continue\n",
    "            indexes.append(value[:1])\n",
    "            y_values.append(value[2:])\n",
    "            \n",
    "    y_values = [int(x) for x in y_values]\n",
    "    \n",
    "    value_counts = Counter(y_values)\n",
    "    class_count = len(value_counts.keys())\n",
    "    \n",
    "print(indexes)\n",
    "print(y_values)\n",
    "print(class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b1a252f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.4403998821753703e-08, 0.36011770367622375, 0.6398240923881531, 5.814163887407631e-05]\n",
      "[0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "51199314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def createJsonFile(accuracy, rmse, mae, precision, recall, f1_score):\n",
    "    data = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Rmse\": rmse,\n",
    "        \"Mae\": mae,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"f1_score\": f1_score\n",
    "    }\n",
    "    \n",
    "    json_data = json.dumps(data)\n",
    "    print(json_data)\n",
    "    \n",
    "    json_path = os.path.join(evaluation_path, \"InitialEvaluation.json\")\n",
    "    \n",
    "    if(os.path.exists(json_path)):\n",
    "        print(\"Initial evaluation is already made.\")\n",
    "        return\n",
    "    else:\n",
    "        with open(json_path, \"w\") as json_file:\n",
    "            json.dump(data, json_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f2506814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Accuracy\": 0.75, \"Rmse\": 0.5, \"Mae\": 0.25, \"Precision\": [\"0.67\", \"1.00\"], \"Recall\": [\"1.00\", \"0.50\"], \"f1_score\": [\"0.80\", \"0.67\"]}\n",
      "Initial evaluation is already made.\n"
     ]
    }
   ],
   "source": [
    "# DO EVALUATION\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "if(len(indexes) != len(predictions)):\n",
    "    print(\"Error: Predictions and y values have different lengths.\")\n",
    "    print(len(predictions))\n",
    "    print(len(indexes))\n",
    "else:\n",
    "    for i, pred in enumerate(predictions):\n",
    "        predictions[i] = round(pred)\n",
    "        \n",
    "    accuracy = accuracy_score(y_values, predictions)\n",
    "    \n",
    "    mse = mean_squared_error(y_values, predictions)\n",
    "    rmse = math.sqrt(mse)\n",
    "    \n",
    "    mae = mean_absolute_error(y_values, predictions)\n",
    "    \n",
    "    report = classification_report(y_values, predictions)\n",
    "    lines = report.split('\\n')\n",
    "    \n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1_score = []\n",
    "    \n",
    "    for i in range(0, class_count):\n",
    "        index = 2 + i\n",
    "        singular_line = lines[index].split()\n",
    "\n",
    "        precision.append(singular_line[1])\n",
    "        recall.append(singular_line[2])\n",
    "        f1_score.append(singular_line[3])\n",
    "\n",
    "    createJsonFile(accuracy, rmse, mae, precision, recall, f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
